---
layout: post
title: 用Python学习自然语言处理
---
该书共500多页,分为11个章节,章节的作用如下:  

| 章节 | 内容 |
| --- | ----------- |
| 1-3 | Python基础与自然语言基础 |
| 4 | 对前面的章节做个回顾 |
| 5-7 | 标注、分类和提取 |
| 8—10 | 解析(parse)、语法结构、意义表示 | 
| 11 | 语言学 |

第3章详细描述了NLP数据底层操作,这个时候涉及到数据的来源,比如来自本地的文件,来自搜索引擎的文件(html网页文件),然后涉及到一些nltk特殊库的运用.
尤其是正则表达式,对文本文件的解析,然后nltk也提供了自带的nltk.tokenise方法.另外,作者特别提到了segmentation(分词?)这一小节应该在第一次阅读时跳过.  
第4章主要是介绍写结构化的Python文件的方法,给语言初学者介绍NLP相关的Python方面的语法. 其中特别地介绍了自然语言处理中用得最多的算法——动态规划。 

---
第5章讲的是Part-of-speech tagging相关的技术,这项技术是自动地给句子中的每一个词归类,动词,形容词,介词等。对一个给定的句子，分析出它的每个词的词性，比如"他(代词)去上学(动词)了(助词)"。一种简单易于理解的办法是建立一个字典，而由于同样一个词在句中不同的位置，表示的词性不一样，那么考虑这个这个字典可以一个键对应多个值。每次要进行标定的时候，就去查询这个词的词性，结合上下文确定词在句中的作用。一种方法是,用正则表达式确定词性.还有方法是建立一系列规则Brill 
Tagging,比如画树,不是先画树,再画蓝天.Brill Tagging是反过来,先粗放型地画蓝天,再画树.最后,应用形态学,语义学等手段对有利于标注,但是每一个绝对正确的标注方法,因为这跟词性的归类有关系,也跟目标有关系.

---  
第6章开始讲的是文本分类,它主要介绍了模型的评价相关参数,比如准确率,召回率,和F1-Score,这几个指标.主要还介绍3种主要模型,决策树,贝叶斯分类器,最大熵分类器.
决策树用来给文本分类的时候，有一个缺陷是在判断feature的时候必须严格按照一定的顺序。而贝叶斯分类器解决了顺序的问题，引入了概率模型的概念。但贝叶斯分类器的缺点是它的一个假定，即feature之间是相互独立没有影响。但现实却不是如此，feature之间往往会相互影响。这就涉及到重复的计算的问题。最大熵分类器的提出是为了解决这个问题的。语言模型分为生成型的条件型的,一般来说,生成型的能力更强,navie贝叶斯是属于生成型的,但是最大熵模型属于条件型的.但更大的能力源自于更多的自由参数,而样本是一定的,所以现实是条件型的效果更好.大多数由语料库生成的模型是描述型的,而不是解释型的.

---  
第7章描述了我最为关心的信息提取的问题.如何从巨量的信息中提取结构化的信息,一般地涉及到正则表达式的运用.


