---
layout: post
title: kafka
tags: kafka 事件驱动
---

# kafka的架构是什么？它的组成成分缺一不可吗？

Kafka架构核心是Broker集群，依赖ZooKeeper进行元数据管理和协调。生产者将消息发送到Broker，消费者从Broker拉取消息。
缺一不可: Broker集群是必须的。ZooKeeper在早期版本是必需的，但新版本中可以通过Raft选举代替，所以不是绝对不可或缺，但强烈推荐使用或替代方案。生产者和消费者是Kafka生态的使用者，不是架构的组成部分，但没有它们Kafka就失去了意义。

# kafka这么优秀，为什么不让所有的微服务通信都用它呢？
Kafka 本质上是异步的消息队列。 如果一个服务需要立即得到另一个服务的响应才能继续执行，使用 Kafka 会引入额外的延迟和复杂性，因为需要通过回调或者额外的消息传递机制来获取响应。同步的 API 调用更适合这种需要即时反馈的场景。

不适合同步阻塞的场景。

即使 Kafka 的性能很高，但相比于直接的内存调用或本地网络调用，消息的发送和接收仍然会引入一定的延迟。 对于对延迟非常敏感的操作，例如用户界面的实时反馈，同步调用可能更合适。


# 哪些具体的业务场景需要kafka？

- 日志收集： 收集服务器、应用程序的日志。

-  用户行为跟踪： 记录用户在网站或应用上的操作行为。

- 事件驱动架构： 不同微服务之间通过事件进行通信。

- 流式数据处理： 实时处理来自传感器、物联网设备等的数据流。

- 消息队列： 用于解耦生产者和消费者，实现异步通信。

- 配置中心： 将配置信息作为消息发布和订阅。

## 什么时候应该使用 Kafka 进行微服务交互？

异步事件通知： 当一个服务的状态发生变化，需要通知其他多个服务时，使用 Kafka 发布事件是非常合适的。例如，订单服务创建订单后，通知库存服务、支付服务、通知服务等。

高吞吐量的数据流处理： 当需要在微服务之间传输大量数据，并且对实时性有一定要求时，Kafka 是一个很好的选择。例如，日志收集、用户行为数据分析等。

解耦服务： 当需要将两个或多个服务完全解耦，避免服务之间的直接依赖时，可以使用 Kafka 作为中间层。

构建事件驱动的架构： Kafka 是构建事件驱动架构的核心组件，允许服务通过事件进行协作，提高系统的灵活性和可扩展性。

消息缓冲和削峰填谷： 当上游服务的请求量非常大，下游服务无法及时处理时，可以使用 Kafka 作为缓冲，平滑请求压力。

# kafka就是生产者消费者模式吗？
Kafka的核心设计模式就是生产者-消费者模式。生产者负责生产消息并发送到Kafka，消费者负责从Kafka订阅和消费消息。

# kafka的队列有多大？如何设置？当超过最大值的时候怎么办？
Kafka 没有固定大小的队列。 它使用主题（Topic）来组织消息，每个主题可以分为多个分区（Partition）。 消息存储在分区中，分区大小受限于磁盘空间和配置的消息保留策略。
如何设置：

消息保留时间（retention.ms）: 设置消息在被删除前保留的时间。
消息保留大小（retention.bytes）: 设置每个分区允许保留的最大数据量。
超过最大值： Kafka会根据配置的保留策略删除旧的消息。常见的策略是删除最旧的消息，也可以配置压缩策略（Compact）来保留每个键的最新消息。



# kafka是中间件吗？还有哪些中间件？
Kafka是一种消息队列中间件。
其他中间件：

消息队列中间件： RabbitMQ, ActiveMQ, RocketMQ

缓存中间件： Redis, Memcached

数据库中间件： MyCat, ShardingSphere

服务治理中间件： Nacos, Eureka, Consul

API网关中间件： Spring Cloud Gateway, Nginx

# 为什么说传统的消息中间件： 例如RabbitMQ, ActiveMQ，功能相对完备，但可能在某些高吞吐量和持久化场景下不如Kafka？
1. 架构设计和持久化机制：

Kafka：面向日志结构和磁盘顺序写入

Kafka 的核心设计是围绕着分布式、持久化的提交日志（commit log）展开的。消息被顺序地追加到磁盘上，这种顺序写入的方式极大地提高了写入速度，因为避免了随机磁盘 I/O。

Kafka 主要依赖操作系统的页缓存（Page Cache）来提高读写性能。操作系统会缓存最近访问过的数据，因此即使数据在磁盘上，消费者也可能从内存中读取到，非常高效。

Kafka 的持久化是其核心特性，所有消息默认都会持久化到磁盘，确保了消息的可靠性。

传统消息中间件：更偏向内存和更复杂的持久化

许多传统消息中间件最初的设计更偏向于内存存储，将消息尽可能地放在内存中以提高速度。

持久化通常是作为额外的功能实现的，可能涉及更复杂的磁盘操作，例如随机写入和事务处理，这会带来一定的性能开销。

虽然它们也支持持久化，但在高并发写入的情况下，磁盘 I/O 可能会成为瓶颈。

2. 消费者模型：

Kafka：拉取 (Pull) 模式

消费者主动从 Broker 拉取消息。这种模式允许消费者控制消费速度，根据自身处理能力来获取消息，避免被生产者压垮。

Broker 无需维护每个消费者的状态，只需要维护每个分区的消费偏移量即可，大大简化了 Broker 的设计，提升了 Broker 的吞吐能力。

传统消息中间件：推送 (Push) 模式

Broker 主动将消息推送给消费者。如果消费者处理速度慢，可能会导致消息堆积，甚至压垮消费者。

Broker 需要维护每个消费者的状态，以及消息的确认机制等，这会增加 Broker 的负担。

3. 消息传递语义和保证：

Kafka：至少一次 (At Least Once)

Kafka 默认提供“至少一次”的交付保证，即消息可能会被重复消费，但不会丢失。这在很多高吞吐量的场景下是可以接受的，可以通过消费者的幂等性来解决重复消费的问题。

传统消息中间件：多种交付保证

许多传统消息中间件提供了更严格的消息交付保证，例如“恰好一次 (Exactly Once)”，这需要更复杂的事务和确认机制，也会带来一定的性能开销。

4. 设计目标和应用场景：

Kafka：高吞吐量、持久化、分布式流处理平台

Kafka 的设计目标是处理大规模的实时数据流，具有极高的吞吐量和可扩展性，适用于日志收集、事件流处理、用户行为跟踪等场景。

传统消息中间件：更通用、功能更丰富

传统消息中间件的设计目标更通用，除了消息队列功能外，通常还提供更丰富的功能，例如消息转换、路由、事务支持等，适用于更广泛的应用场景，例如企业集成、异步任务处理等。

# kafka包含业务逻辑吗？
不包含。Kafka专注于消息的传输、存储和分发，本身不处理具体的业务逻辑。业务逻辑由生产者和消费者应用程序来实现。

# kafka在内存中吗？
不在内存中。Kafka主要将消息持久化到磁盘，利用操作系统的页缓存来提高读写性能。


# kafka 是集群吗？
Kafka通常以集群的方式部署，由多个Broker组成，提供高可用性和高吞吐量。

# kafka是服务吗？
Kafka作为一个服务运行，提供消息队列的功能供其他应用程序使用。


# kafka为什么还要分区？不分区行不行？分区有哪些策略？
为什么要分区：

- 提高吞吐量： 允许并行处理，生产者可以并行写入不同分区，消费者可以并行消费不同分区。

- 提高可扩展性： 可以将主题分布在多个Broker上，实现水平扩展。

- 实现消息顺序性： 保证单个分区内的消息是有序的。

不分区行不行： 理论上可以，但会严重限制吞吐量和可扩展性，成为性能瓶颈。


## 分区策略：

- 轮询（Round Robin）： 默认策略，均匀地将消息发送到各个分区。

- Key哈希： 根据消息的Key进行哈希，将具有相同Key的消息发送到同一个分区，保证相同Key的消息顺序性。

- 自定义分区器： 允许根据业务需求自定义分区策略。


# kafka一定用在分布式应用中吗？
不一定。虽然Kafka非常适合分布式应用，但也可以用于单机应用，例如作为日志收集或事件驱动的系统。只是在高并发、大数据量的场景下，分布式部署的Kafka更能发挥其优势。


# 没有kafka的时候是怎么实现的？
在没有Kafka的时候，类似的需求可以通过以下方式实现：

点对点消息队列： 例如JMS，每个消息只能被一个消费者消费。

传统的消息中间件： 例如RabbitMQ, ActiveMQ，功能相对完备，但可能在某些高吞吐量和持久化场景下不如Kafka。

数据库： 使用数据库作为消息队列，但性能和可靠性可能不如专门的消息队列。

简单的内存队列： 适用于低并发、数据量小的场景，但数据易丢失。


# kafka和mqtt的关系是？有关系吗？

有关系，但定位不同。

Kafka： 面向高吞吐量、持久化、多订阅者的分布式消息流平台，常用于后端服务之间的数据交换和流式处理。

MQTT： 轻量级的消息传输协议，主要用于物联网 (IoT) 设备，特点是低带宽、不可靠网络环境下的稳定传输。

关系： 在某些场景下，可以将 MQTT 作为接入层，将 IoT 设备的数据收集到 Kafka 中进行后续处理和分析。可以理解为 MQTT 负责“最后一公里”的数据接入，而 Kafka 负责大规模数据的存储和处理。 它们可以协同工作，但解决的问题域有所不同。



# 举一个具体的场景说说，kafka事件驱动架构？

场景：用户成功下单

假设我们有以下几个核心微服务：

- 订单服务 (Order Service): 负责处理订单的创建、状态管理等。

- 支付服务 (Payment Service): 负责处理用户的支付请求。

- 库存服务 (Inventory Service): 负责管理商品的库存。

- 通知服务 (Notification Service): 负责发送通知，例如短信、邮件等。

- 物流服务 (Shipping Service): 负责处理订单的发货。

事件驱动流程：

用户在前端发起下单请求。

订单服务接收到请求，验证数据并创建新的订单记录，状态为“待支付”。

订单服务发布一个事件：OrderCreated (订单已创建)。 这个事件中会包含关键信息，例如订单ID、用户ID、商品ID、商品数量、收货地址等。

以下微服务订阅了 OrderCreated 事件，并会异步地处理该事件：

- 支付服务： 接收到 OrderCreated 事件后，知道有新的订单需要支付。它会监听用户的支付行为，等待用户完成支付。

- 库存服务： 接收到 OrderCreated 事件后，会尝试预留订单中商品的库存。注意这里是预留，避免在支付完成前库存就被占用。

- 通知服务： 接收到 OrderCreated 事件后，可以发送下单成功的通知给用户（例如短信或App Push，告知用户订单已提交，请尽快支付）。

用户在前端进行支付操作。

支付服务接收到用户的支付请求，完成支付流程。

支付服务发布一个事件：PaymentSuccessful (支付成功)。 这个事件中会包含订单ID、支付金额、支付时间等信息。

以下微服务订阅了 PaymentSuccessful 事件，并会异步地处理该事件：

- 订单服务： 接收到 PaymentSuccessful 事件后，会将订单状态更新为“已支付”。

- 库存服务： 接收到 PaymentSuccessful 事件后，会将之前预留的库存正式扣减。

- 通知服务： 接收到 PaymentSuccessful 事件后，可以发送支付成功的通知给用户。

- 物流服务： 接收到 PaymentSuccessful 事件后，可以开始进行订单的发货处理流程。

如果没有支付成功，支付服务可能会发布另一个事件：PaymentFailed (支付失败)。 其他服务可以订阅这个事件并采取相应的操作，例如订单服务将订单状态更新为“支付失败”，通知服务发送支付失败的通知等。


# 为什么使用事件驱动？

- 解耦性 (Decoupling): 各个微服务之间不需要知道彼此的存在和具体实现。订单服务只需要发布 OrderCreated 事件，而不需要直接调用支付服务、库存服务或通知服务的接口。其他服务只关注自己感兴趣的事件。

- 异步性 (Asynchronous): 订单服务创建订单后不需要等待支付、库存或通知服务的响应，可以立即返回。这提高了系统的响应速度和吞吐量。

- 可扩展性 (Scalability): 可以独立地扩展各个微服务。例如，如果通知服务压力增大，可以单独扩展通知服务的实例。

- 容错性 (Resilience): 如果某个订阅了事件的服务出现故障，不会影响发布事件的服务。例如，即使库存服务暂时不可用，用户仍然可以下单，只是库存的预留可能会延迟。

- 可观察性 (Observability): 通过追踪事件的流动，可以更容易地理解系统的行为和进行故障排查。

# 使用kafka只需要考虑配置参数就行了？
- 消息存储和管理：

磁盘 I/O 优化： Kafka 实现了高效的磁盘写入和读取机制，例如顺序写入、零拷贝技术等，这些都需要复杂的代码实现。

索引管理： 为了快速定位消息，Kafka 需要维护各种索引（Offset Index, Timestamp Index），这涉及到索引的构建、更新和查找算法。

日志分段和清理： Kafka 需要管理日志文件的切割和过期消息的清理，这涉及到文件操作、时间管理等逻辑。

分布式协调和管理：

- Broker 集群管理： Kafka 需要管理集群中的多个 Broker 节点，包括节点的加入、离开、状态监控等。

- Leader 选举： 当某个 Partition 的 Leader Broker 宕机时，Kafka 需要通过某种选举算法选出新的 Leader，这涉及到复杂的分布式共识算法。

- 元数据管理： Kafka 需要维护 Topic、Partition、Broker 等元数据信息，并在集群中同步这些信息。

- 消息传输和网络通信：

网络协议实现： Kafka 使用自定义的二进制协议进行通信，需要实现协议的编码和解码逻辑。

请求处理： Broker 需要处理来自生产者和消费者的各种请求（例如发送消息、拉取消息、创建 Topic 等）。

连接管理： Kafka 需要管理生产者和消费者与 Broker 之间的连接。

- 数据复制和容错：

副本同步： Kafka 需要将 Partition 的数据同步到多个副本，以保证数据的高可用性，这涉及到复杂的同步机制和状态管理。

ISR (In-Sync Replicas) 管理： Kafka 需要维护同步副本列表，并根据副本的状态进行调整。

- 安全性：

身份验证和授权： Kafka 支持通过 SASL 或 TLS 进行身份验证，并使用 ACL 进行授权管理，这些都需要相应的代码逻辑来实现。

数据加密： Kafka 支持传输加密 (TLS) 和磁盘加密，需要实现加密和解密算法。

- 监控和指标：

指标收集和暴露： Kafka Broker 会收集各种运行指标，并通过 JMX 或其他方式暴露出来，这需要相应的代码逻辑来实现指标的计算和展示。

- API 和客户端交互：

服务端 API 实现： Kafka Broker 需要实现服务端 API，供客户端进行调用。

客户端库实现： Kafka 提供了各种语言的客户端库（例如 Java, Python, Go），这些库的实现包含了与 Broker 通信、消息序列化/反序列化、错误处理等逻辑。

# kafka不包含业务逻辑吗？
虽然 Kafka 本身不包含具体的业务逻辑代码，但它在你的业务系统中扮演着至关重要的角色：

- 异步通信： Kafka 用于解耦不同的服务或组件，允许它们通过异步消息进行通信，提高系统的响应速度和弹性。

- 事件驱动架构： Kafka 可以作为事件总线，用于在不同的微服务之间传递事件，实现事件驱动的架构模式。例如，订单服务发布订单创建事件，库存服务和支付服务监听该事件并进行相应的处理。

- 数据管道： Kafka 可以作为数据管道，用于收集、传输和存储来自不同来源的数据，例如日志、用户行为数据等。

- 流式处理： Kafka 可以与流处理框架（例如 Apache Flink、Kafka Streams）结合使用，进行实时的数据分析和处理。

# Kafka Replicas 的核心管理是什么？

多副本保证高可用: 每个分区有多个副本 (Leader 和 Follower) 分布在不同 Broker 上。

Leader 处理读写: 一个分区的 Leader 副本处理所有生产和消费请求。

Follower 同步数据: Follower 副本从 Leader 复制数据，保持数据一致性。

Controller 负责管理: Controller 负责副本的分配、Leader 选举等管理工作。

ZooKeeper/Kraft 协调: ZooKeeper (或 Kraft) 负责 Leader 的选举和元数据管理。

ISR 保障可靠性: 只有与 Leader 同步的 Follower (ISR) 才有资格成为新的 Leader。

故障自动切换: 当 Leader 故障时，会从 ISR 中选举新的 Leader。

replication-factor 和 min.insync.replicas 控制一致性和可用性。

简单来说，就是多备份、选头头、跟着头头干、坏了换个可靠的头头继续干，配置决定有多可靠。

# Controller 是Leader吗？


你可以把 Kafka 集群想象成一个公司：

Controller 就像公司的 CEO： 负责制定公司战略、管理部门和人员，并做出关键决策（例如选举部门领导）。

Partition Leader 就像部门的经理： 负责管理部门的日常运营、处理部门的事务（例如处理业务请求）。

一个 Broker 可以同时扮演 Controller 和 Partition Leader 的角色。 也就是说，一个 Broker 可以是集群的 Controller，同时也可以是某些 Partition 的 Leader。 但这两个角色是逻辑上分离的，负责不同的管理层面。

因此，明确地说，Controller 不是 Partition Leader。 Controller 负责集群级别的管理和协调，而 Partition Leader 负责特定 Partition 的数据读写和副本管理。

# kafka快的理由

极致的磁盘 I/O 优化 (顺序写入 + 页缓存)。

高效的数据传输 (零拷贝 + 批量处理)。

消费者的主动控制 (拉取模式)。

强大的并行处理能力 (分区 + 分布式架构)。

# 当 Consumer Group 中的消费者实例数量与 Topic 的分区数量不一致时，Kafka 如何决定哪些消费者负责消费哪些分区。

根据预设的分配规则 (策略)，尽可能公平地将分区分配给消费者。

- Range (范围分配): 分区和消费者排序后，按序号划分范围分配，简单但可能不均匀。

- RoundRobin (轮询分配): 分区和消费者排序后，轮流分配，力求均匀，但 Rebalance 时可能全盘重分。

- Sticky (粘性分配): 尽量保留之前的分区分配，Rebalance 时变动小，但实现稍复杂。

- CooperativeSticky (协作式粘性分配): Sticky 的改进版，Rebalance 时消费者分阶段认领分区，减少消费中断。

# 失效副本是指什么？有那些应对措施？
原因简述： Broker 故障、网络问题、磁盘错误等。

后果简述： 降低容错能力，Leader 故障时可能丢失数据。

应对措施简述：

自动 Leader 选举： 失效 Leader 会触发选举，从 ISR 中选出新 Leader。

副本同步： 失效副本恢复后，会追赶 Leader 的数据。

分区重分配： 如果副本永久失效，Controller 会重新分配副本。


# 如何确定当前能读到哪一条消息？

确定当前消费者能读到哪一条消息，关键在于理解 消费者偏移量 (Consumer Offset)。 每个消费者组 (Consumer Group) 针对每个 Topic 的每个分区都有一个独立的偏移量，指向下一条即将被消费的消息。

consumer.position(TopicPartition partition): 这是最直接的方法。调用此方法，传入 TopicPartition 对象（指定 Topic 和分区），它会返回当前消费者在该分区中即将读取的下一条消息的偏移量 (offset)。

consumer.committed(TopicPartition partition): 此方法返回消费者已经成功提交的最后一条消息的偏移量。因此，下一条可读消息的偏移量是 committed offset + 1。 注意，如果消费者使用自动提交，这个值可能不是最新的。

consumer.assignment(): 首先使用此方法获取当前消费者被分配到的所有分区，然后对每个分区调用 consumer.position() 或 consumer.committed()。

# kafka中，生产者发送消息有哪些模式？
同步 (Synchronous): send().get() 生产者发送消息后，会阻塞当前线程，直到收到 Kafka Broker 的确认 (ack) 或者超时。高可靠性，但性能较低。

异步 (Asynchronous): send(callback) 生产者发送消息后立即返回，不会阻塞当前线程。可以通过回调函数 (Callback) 处理发送结果（成功或失败）。高性能，但需要处理回调逻辑。

总结： 主要区别在于是否阻塞发送线程等待确认。同步确保消息被成功发送，异步则更注重吞吐量。

